# -*- coding: utf-8 -*-
"""Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/166AiolhqKhNasphMhQ74S22JihK1ERsg
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder


song_data = pd.read_csv("songs.csv")

#split into train and test data
X = song_data.drop(columns=['popularity']).copy()
y = song_data['popularity'].copy()

songx_train, songx_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)

ct = ColumnTransformer([('minmax', MinMaxScaler(), ['year', 'tempo', 'duration_ms']),
                        ('categorial', OneHotEncoder(), ['key']),
                       ('drop_cols', 'drop', ['name'])],
                       remainder='passthrough')
ct.fit(songx_train)

song_train_Processed = ct.transform(songx_train)
song_test_Processed = ct.transform(songx_test)

def create_model(learning_rate):
    model = tf.keras.models.Sequential()
    model.add(layers.Dense(50, activation = 'relu',kernel_regularizer=tf.keras.regularizers.l2(0.04),input_dim=26))
    model.add(layers.Dense(50, activation = 'relu'))
    model.add(layers.Dropout(0.2))
    model.add(layers.Dense(30, activation = 'relu'))

    model.add(layers.Dense(1, activation = 'linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),
                loss="mean_squared_error",
                metrics=[tf.keras.metrics.MeanSquaredError()])

    return model

def train_model (model, features, label, epochs, batch_size):
    featureTrain = np.array(features)
    labelTrain = np.array(label)
    
    history = model.fit(featureTrain, labelTrain, epochs=epochs, validation_split = 0.3, batch_size=batch_size, verbose =2, 
                       shuffle=True) 
    epochs = history.epoch
    hist = pd.DataFrame(history.history)
    mse = hist["mean_squared_error"]

    return epochs, mse

def plot_the_loss_curve(epochs, mse):
  
    plt.figure()
    plt.xlabel("Epoch")
    plt.ylabel("Mean Squared Error")

    plt.plot(epochs, mse, label="Loss")
    plt.legend()
    plt.ylim([mse.min()*0.95, mse.max() * 1.03])
    plt.show()

learning_rate = 0.01
epochs = 45
batch_size = 50
label_name = "popularity"

model = create_model(learning_rate)
epochs, mse = train_model(model, song_train_Processed, y_train, epochs, batch_size)
plot_the_loss_curve(epochs, mse)

featureTest = np.array(song_test_Processed)
labelTest = np.array(y_test)
model.evaluate(x = featureTest, y = labelTest, batch_size = batch_size)


model.save('trained_model')